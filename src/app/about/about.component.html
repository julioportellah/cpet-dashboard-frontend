<h3>About the CPET</h3>
<h4><b>Designed By:</b> 
    <a href="mailto:joao.mansur@duke.edu">Jo√£o Alberto Mansur</a>, 
    <a href="mailto:julio.portella@duke.edu">Julio Portella</a>, 
    <a href="mailto:derek.wales@duke.edu">Derek Wales</a>
</h4>
<h4><b>Latest update by:</b> <a href="mailto:julio.portella@duke.edu">Julio Portella</a></h4>
<h4>With the support and collaboration from MD. Brian Andonian, MD. William Kraus, PhD. Ed Hammond, PhD. Vivian West</h4>
<h4></h4>
<h4>Data generated by Duke University and the MIDS Health Informatics Team  </h4>
<h4><b>Techniques:</b> Angular,  R(former) (ggplot2, R Shiny)   </h4>  
<p>Feel free to click on my name to email me feedback or suggestions!  
    about works!
    <br>
    <br>
    Have you ever wondered why you were too tired to keep running? is it your heart, lungs, or muscle that failed first when you needed to take a break from your bike?  
    <br>
    <br>
    The Health Informatics and Duke Hospital are trying to not just figure out which of your systems are deficient but also if any of those problems could be indicating a disease.
    <br>
    The Cardiopulmonary Exercise Test (CPET) is a method to assess heart and lung performance that Duke Health uses to understand what's going on when you exercise. Patients perform mild exercise on an upright bicycle or treadmill with ECG sensors on their chest and while breathing through a mouthpiece with gas sensors. Data measured includes Oxygen and CO2 in your breath, Heart Rate, and many more.
    It's not the most legible visualization out there.
    <br>
    <br>
    My team is working with Duke Health experts to improve exercise data accessibility. One of the main initiatives is utilizing logistic regression to predict which systems are responsible for failures to continue exercising. By providing the model scores, doctors can more easily be alerted to patient deficiencies and won't have to learn to read these complicated charts.
    <br>
    <br>
    We created three regression models that take the data from CPET and output three scores between 0 and 1; 0 means there is little risk of a deficiency and 1 means certain deficiency problems. Some athletic individuals may receive scores all below .3 or so while individuals with severe issues may have several deficiency scores above .7.An accurate result therefore is one where a patient has a medical condition and the model assigns a large deficiency score for that patient in the affected systems.
    <br>
    <br>
    We had experts look at patient charts and tell us whether they think that patient had a deficiency in a system or not. Our model trained on that information and was able to match expert assessments at least 80% of the time. 
    <br>
    <br>
    We also asked experts to tell us if the patient had any particular condition or illness, so we could see if the model was capable of alerting doctors to the presence of any illness.
    <br>
    <br>
    This particular visualization below was created to check model results with our medical experts. This leads to this dynamism: 
    <br>
    <br>
    It has interface two teams:    
    The team that developed the model, interested in how the model performed and where it is succeeding/failing.    
    The medical experts who want to compare patient conditions or illnesses to their model results.  
    <br>
    <br>
    The choice of visualizations came down to model assessment. The team needed to:  
    1. Highlight particular IDs when doctors ask to check them  
    2. Clearly display their predicted deficiency scores and their condition, so doctors can see if the deficiency levels make sense with the diagnosis
    3. Show the team where the patient falls in the overall performance of the three models.    
</p>